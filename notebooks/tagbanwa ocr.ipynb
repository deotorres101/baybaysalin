{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1239accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49146f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Project Files | LOAD\n",
    "IMAGE_DIR = 'dataset'\n",
    "\n",
    "FILE_LIST_TEMP = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(IMAGE_DIR):\n",
    "    for filename in filenames:\n",
    "        FILE_LIST_TEMP.append(os.path.join(dirname, filename))\n",
    "        \n",
    "# creating the finalized file list and label list\n",
    "FILE_LIST = []\n",
    "LABELS = []\n",
    "\n",
    "for FILE_PATH in FILE_LIST_TEMP:\n",
    "    label = FILE_PATH.split(os.path.sep)[-2]\n",
    "    \n",
    "    FILE_LIST.append(FILE_PATH)\n",
    "    LABELS.append(label)\n",
    "\n",
    "\n",
    "# Variables for pre-processing and training.\n",
    "BATCH_SIZE = 32 # the higher the number, baka di na kayanin ng pc hahaha\n",
    "epochs = 50 # number of times the model will be trained\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aef28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/ya/_15_3554111.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/ya/_13_7835852.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/ya/_19_8719555.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/ya/_1_1099932.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/ya/_19_3373455.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>dataset/la/_4_9041232.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>dataset/la/_19_2616786.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>dataset/la/_19_9196768.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>dataset/la/_12_6735828.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>dataset/la/_0_8043580.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        File path Label\n",
       "0      dataset/ya/_15_3554111.png    ya\n",
       "1      dataset/ya/_13_7835852.png    ya\n",
       "2      dataset/ya/_19_8719555.png    ya\n",
       "3       dataset/ya/_1_1099932.png    ya\n",
       "4      dataset/ya/_19_3373455.png    ya\n",
       "...                           ...   ...\n",
       "41995   dataset/la/_4_9041232.png    la\n",
       "41996  dataset/la/_19_2616786.png    la\n",
       "41997  dataset/la/_19_9196768.png    la\n",
       "41998  dataset/la/_12_6735828.png    la\n",
       "41999   dataset/la/_0_8043580.png    la\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(FILE_LIST, LABELS)), columns = ['File path', 'Label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6458722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/ta/_5_9256839.png</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/i/_18_4553740.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/li/_8_5253537.png</td>\n",
       "      <td>li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/ba/_12_117114.png</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/da/_13_4090745.png</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>dataset/yi/_4_8528050.png</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>dataset/su/_2_5193815.png</td>\n",
       "      <td>su</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>dataset/mu/_1_9700709.png</td>\n",
       "      <td>mu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>dataset/bi/_8_7719943.png</td>\n",
       "      <td>bi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>dataset/li/_15_5934001.png</td>\n",
       "      <td>li</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        File path Label\n",
       "0       dataset/ta/_5_9256839.png    ta\n",
       "1       dataset/i/_18_4553740.png     i\n",
       "2       dataset/li/_8_5253537.png    li\n",
       "3       dataset/ba/_12_117114.png    ba\n",
       "4      dataset/da/_13_4090745.png    da\n",
       "...                           ...   ...\n",
       "41995   dataset/yi/_4_8528050.png    yi\n",
       "41996   dataset/su/_2_5193815.png    su\n",
       "41997   dataset/mu/_1_9700709.png    mu\n",
       "41998   dataset/bi/_8_7719943.png    bi\n",
       "41999  dataset/li/_15_5934001.png    li\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d03d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for splitting train and testing dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.25\n",
    "\n",
    "train, test = train_test_split(df, test_size = test_ratio)\n",
    "val, test = train_test_split(test, test_size=test_ratio/(test_ratio + validation_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12d3508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31500 validated image filenames belonging to 42 classes.\n",
      "Found 3000 validated image filenames belonging to 42 classes.\n",
      "Found 7500 validated image filenames belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "# PRE PROCESS\n",
    "# creating an image data generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "x_train = img_datagen.flow_from_dataframe(dataframe=train, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')\n",
    "\n",
    "x_val = img_datagen.flow_from_dataframe(dataframe=val, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')\n",
    "\n",
    "x_test = img_datagen.flow_from_dataframe(dataframe=test, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), shuffle=False, batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4501a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PANG PLOT ITO\n",
    "def plotImages(images_arr, probabilities = False):\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_training_images, _ = next(x_train)\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2e9b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(img_height, img_width, output_layer):\n",
    "    # BUILD THE MODEL\n",
    "    # CNN Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(img_height, img_width, 1))) # Input Layer\n",
    "    # Subsequent Layes | Hidden Layer\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "    #Dense layers | Pang-classify\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(output_layer))\n",
    "\n",
    "    #Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90309a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:04:00.282331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.288750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.289135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.289851: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 15:04:00.290117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.290478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.290811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.597612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.597912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.598186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:04:00.598424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2011 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:07:00.0, compute capability: 7.5\n",
      "2021-11-07 15:04:00.685507: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 42)                2730      \n",
      "=================================================================\n",
      "Total params: 124,074\n",
      "Trainable params: 124,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:04:01.315022: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985/985 [==============================] - 88s 86ms/step - loss: 1.8452 - accuracy: 0.4241 - val_loss: 1.0783 - val_accuracy: 0.6220\n",
      "Epoch 2/50\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.8175 - accuracy: 0.7141 - val_loss: 0.7100 - val_accuracy: 0.7467\n",
      "Epoch 3/50\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.5742 - accuracy: 0.7961 - val_loss: 0.6217 - val_accuracy: 0.7820\n",
      "Epoch 4/50\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.4531 - accuracy: 0.8390 - val_loss: 0.4650 - val_accuracy: 0.8410\n",
      "Epoch 5/50\n",
      "985/985 [==============================] - 17s 18ms/step - loss: 0.3694 - accuracy: 0.8680 - val_loss: 0.5090 - val_accuracy: 0.8340\n",
      "Epoch 6/50\n",
      "985/985 [==============================] - 17s 18ms/step - loss: 0.3256 - accuracy: 0.8841 - val_loss: 0.4844 - val_accuracy: 0.8353\n",
      "Epoch 7/50\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.2847 - accuracy: 0.8985 - val_loss: 0.4135 - val_accuracy: 0.8593\n",
      "Epoch 8/50\n",
      "985/985 [==============================] - 18s 18ms/step - loss: 0.2500 - accuracy: 0.9097 - val_loss: 0.4664 - val_accuracy: 0.8533\n",
      "Epoch 9/50\n",
      "985/985 [==============================] - 18s 18ms/step - loss: 0.2317 - accuracy: 0.9179 - val_loss: 0.4290 - val_accuracy: 0.8623\n",
      "Epoch 10/50\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.2004 - accuracy: 0.9270 - val_loss: 0.4637 - val_accuracy: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:08:03.888604: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/tagbanwa_model/assets\n"
     ]
    }
   ],
   "source": [
    "# FIT THE DATA TO THE MODEL\n",
    "save_dir = 'models'\n",
    "saved_model = 'tagbanwa_model'\n",
    "OUTPUT_LAYERS = len(list(x_train.class_indices.keys()))\n",
    "PATIENCE = 3\n",
    "\n",
    "if saved_model not in os.listdir():\n",
    "    model = build_model(IMG_HEIGHT, IMG_WIDTH, OUTPUT_LAYERS)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=PATIENCE,\n",
    "                                                mode='min')\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=x_val,\n",
    "                       callbacks=early_stopping)\n",
    "    model.save(os.path.join(save_dir, saved_model))\n",
    "    model.save(f'{os.path.join(save_dir, saved_model)}.h5')\n",
    "else:\n",
    "    model = tf.keras.models.load_model(os.path.join(save_dir, saved_model))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a1240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 17s 74ms/step - loss: 0.4685 - accuracy: 0.8561\n",
      "Test accuracy is :  85.61333417892456 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(x_test)[1] * 100\n",
    "print('Test accuracy is : ',test_accuracy, '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb1d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'ba': 1, 'bi': 2, 'bu': 3, 'da': 4, 'di': 5, 'du': 6, 'ga': 7, 'gi': 8, 'gu': 9, 'i': 10, 'ka': 11, 'ki': 12, 'ku': 13, 'la': 14, 'li': 15, 'lu': 16, 'ma': 17, 'mi': 18, 'mu': 19, 'na': 20, 'nga': 21, 'ngi': 22, 'ngu': 23, 'ni': 24, 'nu': 25, 'pa': 26, 'pi': 27, 'pu': 28, 'sa': 29, 'si': 30, 'su': 31, 'ta': 32, 'ti': 33, 'tu': 34, 'u': 35, 'wa': 36, 'wi': 37, 'wu': 38, 'ya': 39, 'yi': 40, 'yu': 41}\n"
     ]
    }
   ],
   "source": [
    "# Show class index\n",
    "print(x_train.class_indices)\n",
    "baybayin_classes = list(x_train.class_indices.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
