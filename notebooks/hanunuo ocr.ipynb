{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1239accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49146f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Project Files | LOAD\n",
    "IMAGE_DIR = 'dataset'\n",
    "\n",
    "FILE_LIST_TEMP = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(IMAGE_DIR):\n",
    "    for filename in filenames:\n",
    "        FILE_LIST_TEMP.append(os.path.join(dirname, filename))\n",
    "        \n",
    "# creating the finalized file list and label list\n",
    "FILE_LIST = []\n",
    "LABELS = []\n",
    "\n",
    "for FILE_PATH in FILE_LIST_TEMP:\n",
    "    label = FILE_PATH.split(os.path.sep)[-2]\n",
    "    \n",
    "    FILE_LIST.append(FILE_PATH)\n",
    "    LABELS.append(label)\n",
    "\n",
    "\n",
    "# Variables for pre-processing and training.\n",
    "BATCH_SIZE = 32 # the higher the number, baka di na kayanin ng pc hahaha\n",
    "epochs = 50 # number of times the model will be trained\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aef28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/ya/_3_5509983.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/ya/_10_5506981.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/ya/_9_3422722.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/ya/_1_7534464.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/ya/_2_6948069.png</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62995</th>\n",
       "      <td>dataset/la/_0_9429944.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62996</th>\n",
       "      <td>dataset/la/_2_3522546.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62997</th>\n",
       "      <td>dataset/la/_0_2781433.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62998</th>\n",
       "      <td>dataset/la/_1_4777432.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62999</th>\n",
       "      <td>dataset/la/_4_1698629.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        File path Label\n",
       "0       dataset/ya/_3_5509983.png    ya\n",
       "1      dataset/ya/_10_5506981.png    ya\n",
       "2       dataset/ya/_9_3422722.png    ya\n",
       "3       dataset/ya/_1_7534464.png    ya\n",
       "4       dataset/ya/_2_6948069.png    ya\n",
       "...                           ...   ...\n",
       "62995   dataset/la/_0_9429944.png    la\n",
       "62996   dataset/la/_2_3522546.png    la\n",
       "62997   dataset/la/_0_2781433.png    la\n",
       "62998   dataset/la/_1_4777432.png    la\n",
       "62999   dataset/la/_4_1698629.png    la\n",
       "\n",
       "[63000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(FILE_LIST, LABELS)), columns = ['File path', 'Label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6458722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/sa/_5_440146.png</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/wu/_4_126206.png</td>\n",
       "      <td>wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/gu/_3_5392970.png</td>\n",
       "      <td>gu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/yu/_3_1462945.png</td>\n",
       "      <td>yu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/a/_0_9171424.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62995</th>\n",
       "      <td>dataset/k/_4_1273399.png</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62996</th>\n",
       "      <td>dataset/si/_3_3612564.png</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62997</th>\n",
       "      <td>dataset/ni/_4_3503415.png</td>\n",
       "      <td>ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62998</th>\n",
       "      <td>dataset/la/_2_1811414.png</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62999</th>\n",
       "      <td>dataset/yi/_4_1704206.png</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       File path Label\n",
       "0       dataset/sa/_5_440146.png    sa\n",
       "1       dataset/wu/_4_126206.png    wu\n",
       "2      dataset/gu/_3_5392970.png    gu\n",
       "3      dataset/yu/_3_1462945.png    yu\n",
       "4       dataset/a/_0_9171424.png     a\n",
       "...                          ...   ...\n",
       "62995   dataset/k/_4_1273399.png     k\n",
       "62996  dataset/si/_3_3612564.png    si\n",
       "62997  dataset/ni/_4_3503415.png    ni\n",
       "62998  dataset/la/_2_1811414.png    la\n",
       "62999  dataset/yi/_4_1704206.png    yi\n",
       "\n",
       "[63000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d03d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for splitting train and testing dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.25\n",
    "\n",
    "train, test = train_test_split(df, test_size = test_ratio)\n",
    "val, test = train_test_split(test, test_size=test_ratio/(test_ratio + validation_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12d3508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47250 validated image filenames belonging to 63 classes.\n",
      "Found 4500 validated image filenames belonging to 63 classes.\n",
      "Found 11250 validated image filenames belonging to 63 classes.\n"
     ]
    }
   ],
   "source": [
    "# PRE PROCESS\n",
    "# creating an image data generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "x_train = img_datagen.flow_from_dataframe(dataframe=train, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')\n",
    "\n",
    "x_val = img_datagen.flow_from_dataframe(dataframe=val, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')\n",
    "\n",
    "x_test = img_datagen.flow_from_dataframe(dataframe=test, x_col=\"File path\", y_col=\"Label\",\n",
    "                                         target_size=(IMG_HEIGHT,IMG_WIDTH), shuffle=False, batch_size=BATCH_SIZE, class_mode='sparse', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4501a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PANG PLOT ITO\n",
    "def plotImages(images_arr, probabilities = False):\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_training_images, _ = next(x_train)\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2e9b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(img_height, img_width, output_layer):\n",
    "    # BUILD THE MODEL\n",
    "    # CNN Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(img_height, img_width, 1))) # Input Layer\n",
    "    # Subsequent Layes | Hidden Layer\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "    #Dense layers | Pang-classify\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(output_layer))\n",
    "\n",
    "    #Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90309a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:32:04.546312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.551912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.552326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.553131: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 15:32:04.553434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.553802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.554170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.876383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.876682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.876939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-07 15:32:04.877172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2016 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:07:00.0, compute capability: 7.5\n",
      "2021-11-07 15:32:04.984438: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 63)                4095      \n",
      "=================================================================\n",
      "Total params: 125,439\n",
      "Trainable params: 125,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:32:05.668351: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477/1477 [==============================] - 276s 184ms/step - loss: 2.0959 - accuracy: 0.4123 - val_loss: 0.9370 - val_accuracy: 0.7087\n",
      "Epoch 2/50\n",
      "1477/1477 [==============================] - 59s 40ms/step - loss: 0.7269 - accuracy: 0.7650 - val_loss: 0.6348 - val_accuracy: 0.7980\n",
      "Epoch 3/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.4749 - accuracy: 0.8440 - val_loss: 0.4951 - val_accuracy: 0.8342\n",
      "Epoch 4/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.3557 - accuracy: 0.8803 - val_loss: 0.4375 - val_accuracy: 0.8573\n",
      "Epoch 5/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.2880 - accuracy: 0.9021 - val_loss: 0.4009 - val_accuracy: 0.8787\n",
      "Epoch 6/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.2495 - accuracy: 0.9168 - val_loss: 0.2959 - val_accuracy: 0.9064\n",
      "Epoch 7/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.2246 - accuracy: 0.9240 - val_loss: 0.3124 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.1985 - accuracy: 0.9342 - val_loss: 0.3096 - val_accuracy: 0.9078\n",
      "Epoch 9/50\n",
      "1477/1477 [==============================] - 32s 22ms/step - loss: 0.1782 - accuracy: 0.9406 - val_loss: 0.3056 - val_accuracy: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:41:25.587568: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/hanunuo_model/assets\n"
     ]
    }
   ],
   "source": [
    "# FIT THE DATA TO THE MODEL\n",
    "save_dir = 'models'\n",
    "saved_model = 'hanunuo_model'\n",
    "OUTPUT_LAYERS = len(list(x_train.class_indices.keys()))\n",
    "PATIENCE = 3\n",
    "\n",
    "if saved_model not in os.listdir(save_dir):\n",
    "    model = build_model(IMG_HEIGHT, IMG_WIDTH, OUTPUT_LAYERS)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=PATIENCE,\n",
    "                                                mode='min')\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=x_val,\n",
    "                       callbacks=early_stopping)\n",
    "    model.save(os.path.join(save_dir, saved_model))\n",
    "    model.save(f'{os.path.join(save_dir, saved_model)}.h5')\n",
    "else:\n",
    "    model = tf.keras.models.load_model(os.path.join(save_dir, saved_model))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a1240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 71s 202ms/step - loss: 0.3203 - accuracy: 0.9088\n",
      "Test accuracy is :  90.88000059127808 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(x_test)[1] * 100\n",
    "print('Test accuracy is : ',test_accuracy, '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb1d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'ba': 2, 'bi': 3, 'bu': 4, 'd': 5, 'da': 6, 'di': 7, 'du': 8, 'g': 9, 'ga': 10, 'gi': 11, 'gu': 12, 'h': 13, 'ha': 14, 'hi': 15, 'hu': 16, 'i': 17, 'k': 18, 'ka': 19, 'ki': 20, 'ku': 21, 'l': 22, 'la': 23, 'li': 24, 'lu': 25, 'm': 26, 'ma': 27, 'mi': 28, 'mu': 29, 'n': 30, 'na': 31, 'ng': 32, 'nga': 33, 'ngi': 34, 'ngu': 35, 'ni': 36, 'nu': 37, 'p': 38, 'pa': 39, 'pi': 40, 'pu': 41, 'r': 42, 'ra': 43, 'ri': 44, 'ru': 45, 's': 46, 'sa': 47, 'si': 48, 'su': 49, 't': 50, 'ta': 51, 'ti': 52, 'tu': 53, 'u': 54, 'w': 55, 'wa': 56, 'wi': 57, 'wu': 58, 'y': 59, 'ya': 60, 'yi': 61, 'yu': 62}\n"
     ]
    }
   ],
   "source": [
    "# Show class index\n",
    "print(x_train.class_indices)\n",
    "baybayin_classes = list(x_train.class_indices.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
